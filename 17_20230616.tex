\documentclass{jsarticle}
% \documentclass[b4paper,landscape,14pt]{jsarticle}
\title{}
\author{}
\date{
% \number\year 年 \number\month 月
}
\usepackage{fenrir_v1_4_0}
\usepackage{ethm_v1_1_0}
\mathtoolsset{showonlyrefs=true}

\begin{document}
% \maketitle
\setcounter{section}{7}
\section{Stochastic Differential Equations}
\setcounter{subsection}{2}
\subsection{Solutions of Stochastic Differential Equations as Markov Processes}

コンパクトサポートを持つ $\real^d$ 上の二階連続的微分可能な実数値関数全体の集合を $C_c^2(\mathbb{R}^d)$ と表す：
\begin{align}
    C_c^2(\mathbb{R}^d)
    := \{f\in C^2(\mathbb{R}^d):\operatorname{supp}(f)\text{ はコンパクト}\}
\end{align}

\setcounter{thm}{6}
\begin{screen}
    \begin{thm}\label{thm:807}~
        \begin{enumerate}[label=(\arabic*)]
            \item
            $(Q_t)_{t\ge0}$ は Feller 半群である．
            \item
            $(Q_t)_{t\ge0}$ の生成作用素 $L$ は
            \begin{align}
                C_c^2(\mathbb{R}^d)
                \subset D(L)
            \end{align}
            を満たし，任意の $f\in C_c^2(\mathbb{R}^d)$ に対して
            \begin{align}
                Lf(x)
                = \frac{1}{2}\sum_{i, j=1}^{d}(\sigma\sigma^{\ast})_{ij}(x)\frac{\partial^{2}f}{\partial x_{i}\partial x_{j}}(x)
                + \sum_{i=1}^{d}b_{i}(x)\frac{\partial f}{\partial x_{i}}(x)
            \end{align}
            が成り立つ（ただし $\sigma^{\ast}$: $\sigma$ の転置行列）．
        \end{enumerate}
    \end{thm}
\end{screen}

\begin{proof}
    簡単のため，$\sigma, b$ が有界の場合のみ示す（一般の場合？）．
    \begin{enumerate}[label=(\arabic*)]
        \item
        示すべきことは
        \begin{enumerate}[label=(\roman*)]
            \item
            $\forall f\in C_{0}(\mathbb{R}^d), Q_{t}f\in C_{0}(\mathbb{R}^d)$
            \item
            $\forall f\in C_{0}(\mathbb{R}^d), \lVert Q_{t}f-f\rVert\xrightarrow{t\to0}0$
        \end{enumerate}
        の 2 つ．

        $f\in C_{0}(\mathbb{R}^d)$: 固定．
        \begin{enumerate}[label=(\roman*)]
            \item
            $n\to\infty$ としたとき $x_{n}\to x_{0}$ となる点列 $\{x_{n}\}_{n}$ をとる．
            各 $n\ge1$ に対し $\lvert f(F_{x_n}(w)_{t})\rvert\le\lVert f\rVert$ より優収束定理から
            \begin{align}
                \lim_{n\to\infty}Q_{t}f(x_{n})
                &= \lim_{n\to\infty}\int_{C(\mathbb{R_+}, \mathbb{R}^{m})}f(F_{x_{n}}(w)_{t})W(dw) \\
                &= \int_{C(\mathbb{R_+}, \mathbb{R}^{m})}\lim_{n\to\infty}f(F_{x_{n}}(w)_{t})W(dw) \\
                &= \int_{C(\mathbb{R_+}, \mathbb{R}^{m})}f(F_{x_{0}}(w)_{t})W(dw)
                \quad\text{（$\because x\mapsto F_{x}(w)$ と $f$ の連続性）} \\
                &= Q_{t}f(x_{0})
            \end{align}
            より $Q_{t}f$: 連続．
            \begin{align}
                X_{t}^{x}
                = x
                + \int_{0}^{t}\sigma(X_{s}^{x})dB_{s}
                + \int_{0}^{t}b(X_{s}^{x})ds
            \end{align}
            と書けることと，$\sigma, b$: 有界より
            \begin{align}
                E[\lvert X_{t}^{x}-x\rvert^2]
                &= E[\lvert \int_{0}^{t}\sigma(X_{s}^{x})dB_{s}
                + \int_{0}^{t}b(X_{s}^{x})ds\rvert^2] \\
                &\le 2(E[\lvert \int_{0}^{t}\sigma(X_{s}^{x})dB_{s})^2]
                + E[(\int_{0}^{t}b(X_{s}^{x})ds\rvert^2]) \\
                &\le 2(E[\int_{0}^{t}\lvert \sigma(X_{s}^{x})\rvert^{2}ds]
                + tE[\int_{0}^{t}\lvert b(X_{s}^{x})\rvert^{2}ds]) \\
                &\le 2(C_1^2 t+C_2^2 t^2) \\
                &\le (2C_1^2\vee 2C_2^2)(t+t^2).
            \end{align}

            ここで $C:=2C_1^2\vee 2C_2^2$ と定めると，これは $t, x$ に依らない定数で
            \setcounter{equation}{3}
            \begin{align}
                \sup_{x\in\mathbb{R}^d}E[\lvert X_{t}^{x}-x\rvert^2]
                \le C(t+t^2).
                \label{eq:804}
            \end{align}

            $\forall t\ge0$ に対し，Markov の不等式（Chebyshev の不等式の特別な場合）と \eqref{eq:804} より
            \begin{align}
                \sup_{x\in\mathbb{R}^d}P(\lvert X_{t}^{x}-x\rvert>A)
                &\le \sup_{x\in\mathbb{R}^d}\frac{E[\lvert X_{t}^{x}-x\rvert^2]}{A^2} \\
                &\le \frac{C(t+t^2)}{A^2}\xrightarrow{A\to\infty}0.
            \end{align}

            一方
            \begin{align}
                \lvert Q_{t}f(x)\rvert
                &\le E[\lvert f(X_{t}^{x})\rvert] \\
                &= E[\lvert f(X_{t}^{x})\rvert\bm{1}_{\{\lvert X_{t}^{x}-x\rvert\le A\}}]
                + E[\lvert f(X_{t}^{x})\rvert\bm{1}_{\{\lvert X_{t}^{x}-x\rvert>A\}}] \\
                &\le E[\lvert f(X_{t}^{x})\rvert\bm{1}_{\{\lvert X_{t}^{x}-x\rvert\le A\}}]
                + \lVert f\rVert P(\lvert X_{t}^{x}-x\rvert>A).
            \end{align}

            これと $f\in C_{0}(\mathbb{R}^d)$ より
            \begin{align}
                \limsup_{\lvert x\rvert\to\infty}\lvert Q_{t}f(x)\rvert
                &\le \limsup_{\lvert x\rvert\to\infty}(\sup_{y\in\mathbb{R}^d, \lvert x-y\rvert\le A}\lvert f(y)\rvert)
                + \lVert f\rVert \sup_{x\in\mathbb{R}^d}P(\lvert X_{t}^{x}-x\rvert>A) \\
                &\le \frac{\lVert f\rVert C(t+t^2)}{A^2}.
            \end{align}

            よって $A$ の任意性より $\limsup_{\lvert x\rvert\to\infty}\lvert Q_{t}f(x)\rvert=0.$
            したがって $\lim_{\lvert x\rvert\to\infty}\lvert Q_{t}f(x)\rvert=0$ より 
            \begin{align}
                \lim_{\lvert x\rvert\to\infty}Q_{t}f(x)=0.
            \end{align}

            以上より $Q_{t}f$ は $\mathbb{R}^d$ 上の実数値連続関数で $\lim_{\lvert x\rvert\to\infty}Q_{t}f(x)=0$ を満たすので $Q_{t}f\in C_{0}(\mathbb{R}^d).$
                
            \item
            $\forall \varepsilon>0$: 固定．
            \begin{align}
                \lvert E[f(X_{t}^{x})]-f(x)\rvert
                &\le E[\lvert f(X_{t}^{x})-f(x)\rvert\bm{1}_{\{\lvert X_{t}^{x}-x\rvert\le \varepsilon\}}]
                + E[\lvert f(X_{t}^{x})-f(x)\rvert\bm{1}_{\{\lvert X_{t}^{x}-x\rvert>\varepsilon\}}] \\
                &\le \sup_{y\in\mathbb{R}^d, \lvert x-y\rvert<\varepsilon}\lvert f(x)-f(y)\rvert
                + 2\lVert f\rVert P(\lvert X_{t}^{x}-x\rvert>\varepsilon).
            \end{align}
            \begin{align}
                \therefore 
                &\sup_{x\in\mathbb{R}^d}\lvert E[f(X_{t}^{x})]-f(x)\rvert \\
                &\le \sup_{x, y\in\mathbb{R}^d, \lvert x-y\rvert<\varepsilon}\lvert f(x)-f(y)\rvert
                + 2\lVert f\rVert\sup_{x\in\mathbb{R}^d} P(\lvert X_{t}^{x}-x\rvert>\varepsilon).
            \end{align}

            ここで \eqref{eq:804} 及び Markov の不等式より
            \begin{align}
                \sup_{x\in\mathbb{R}^d}P(\lvert X_{t}^{x}-x\rvert>\varepsilon)
                \le \frac{C(t+t^2)}{\varepsilon^2}\xrightarrow{t\to0}0.
            \end{align}

            よって
            \begin{align}
                \limsup_{t\to0}\lVert Q_{t}f-f\rVert
                &= \limsup_{t\to0}(\sup_{x\in\mathbb{R}^d}\lvert E[f(X_{t}^{x})]-f(x)\rvert) \\
                &\le \sup_{x, y\in\mathbb{R}^d, \lvert x-y\rvert<\varepsilon}\lvert f(x)-f(y)\rvert
                + 2\lVert f\rVert\lim_{t\to0}\sup_{x\in\mathbb{R}^d}P(\lvert X_{t}^{x}-x\rvert>\varepsilon) \\
                &= \sup_{x, y\in\mathbb{R}^d, \lvert x-y\rvert<\varepsilon}\lvert f(x)-f(y)\rvert
            \end{align}
            となるが，$f$ の一様連続性より $\varepsilon$ を十分小さくとれば LHS $=0.$
            したがって $\lim_{t\to0}\lVert Q_{t}f-f\rVert.$
        \end{enumerate}

        以上より $(Q_{t})_{t\ge0}$ は Feller 半群であることが示された．
        
        \item
        $f\in C_{c}^2(\mathbb{R}^d)$ とする．
        $f(X_{t}^{x})=f(X_{t}^{x, 1},\dotsb, X_{t}^{x, d})$ に対し It\^{o}'s formula を適用すると
        \begin{align}
            f(X_{t}^{x})
            &= f(x)
            + \sum_{i=1}^{d}\int_{0}^{t}\frac{\partial f}{\partial x_{i}}(X_{s}^{x})dX_{s}^{x, i}
            + \frac{1}{2}\sum_{i, i'=1}^{d}\int_{0}^{t}\frac{\partial f^2}{\partial x_{i}\partial x_{i'}}(X_{s}^{x})d\langle X^{x, i}, X^{x, i'}\rangle_{s}.
        \end{align}

        ここで
        \begin{itemize}
            \item 
            $\displaystyle X_{t}^{x, i}
            = x_i
            + \sum_{j=1}^{m}\int_{0}^{t}\sigma_{ij}(X_{s}^{x})dB_{s}^{j}
            + \int_{0}^{t}b_{i}(X_{s}^{x})ds$
            \item 
            $\displaystyle \langle X^{x, i}, X^{x, i'}\rangle_{s}
            = \sum_{j=1}^{m}\int_0^t\sigma_{ij}(X_{s}^{x})\sigma_{i'j}(X_{s}^{x})ds
            = \int_0^t(\sigma\sigma^{\ast})_{ii'}(X_{s}^{x})ds$
        \end{itemize}
        が成り立つ．

        \begin{screen}
            $\because)$
            \begin{align}
                \langle X^{x, i}, X^{x, i'}\rangle_{t}
                &= \left\langle \sum_{j=1}^{m}\int_{0}^{\cdot}\sigma_{ij}(X_{s}^{x})dB_{s}^{j},
                \sum_{j=1}^{m}\int_{0}^{\cdot}\sigma_{i'j}(X_{s}^{x})dB_{s}^{j}\right\rangle_{t} \\
                &= \sum_{j=1}^{m}\int_{0}^{t}\sigma_{ij}(X_{s}^{x})\sigma_{i'j}(X_{s}^{x})ds.
            \end{align}

            また $\sigma\sigma^{\ast}$（$d\times d$ 行列）の $ii'$ 成分を実際に計算すると $\sum_{j=1}^{m}\sigma_{ij}\sigma_{i'j}$ となることがわかる．
        \end{screen}
        
        これらより
        \begin{align}
            f(X_{t}^{x})
            &=
            \begin{multlined}[t]
                f(x)
                + \sum_{i=1}^{d}\left\{\sum_{j=1}^{m}\int_{0}^{t}\sigma_{ij}(X_{s}^{x})\frac{\partial f}{\partial x_{i}}(X_{s}^{x})dB_{s}^{j}
                + \int_{0}^{t}b_{i}(X_{s}^{x})\frac{\partial f}{\partial x_{i}}(X_{s}^{x})ds\right\} \\
                + \frac{1}{2}\sum_{i, i'=1}^{d}\int_{0}^{t}(\sigma\sigma^{\ast})_{ii'}(X_{s}^{x})\frac{\partial f^2}{\partial x_{i}\partial x_{i'}}(X_{s}^{x})ds
            \end{multlined} \\
            &=
            \begin{multlined}[t]
                f(x)
                + \UB{\sum_{i=1}^{d}\sum_{j=1}^{m}\int_{0}^{t}\sigma_{ij}(X_{s}^{x})\frac{\partial f}{\partial x_{i}}(X_{s}^{x})dB_{s}^{j}}{=:M_{t}\text{ (CLM)}}
                + \sum_{i=1}^{d}\int_{0}^{t}b_{i}(X_{s}^{x})\frac{\partial f}{\partial x_{i}}(X_{s}^{x})ds \\
                + \frac{1}{2}\sum_{i, i'=1}^{d}\int_{0}^{t}(\sigma\sigma^{\ast})_{ii'}(X_{s}^{x})\frac{\partial f^2}{\partial x_{i}\partial x_{i'}}(X_{s}^{x})ds
            \end{multlined} \\
            &=
            \begin{multlined}[t]
                f(x)
                + M_{t}
                + \sum_{i=1}^{d}\int_{0}^{t}b_{i}(X_{s}^{x})\frac{\partial f}{\partial x_{i}}(X_{s}^{x})ds \\
                + \frac{1}{2}\sum_{i, i'=1}^{d}\int_{0}^{t}(\sigma\sigma^{\ast})_{ii'}(X_{s}^{x})\frac{\partial f^2}{\partial x_{i}\partial x_{i'}}(X_{s}^{x})ds.
            \end{multlined}
        \end{align}

        ここで
        \begin{align}
            g(x)
            := \frac{1}{2}\sum_{i, i'=1}^{d}(\sigma\sigma^{\ast})_{ii'}(x)\frac{\partial f^2}{\partial x_{i}\partial x_{i'}}(x)
            + \sum_{i=1}^{d}b_{i}(x)\frac{\partial f}{\partial x_{i}}(x)
        \end{align}
        と定めると，$\forall i, i'=\{1,\dotsb, d\}$ に対し $\frac{\partial f^2}{\partial x_{i}\partial x_{i'}}, \frac{\partial f}{\partial x_{i}}$ はコンパクトサポートを持つので
        \begin{align}
            \frac{\partial f^2}{\partial x_{i}\partial x_{i'}}, \frac{\partial f}{\partial x_{i}}\in C_{0}(\mathbf{R}^d).
        \end{align}
        
        これより $g\in C_{0}(\mathbb{R}^d).$
        この $g$ を用いて
        \begin{align}
            M_{t}
            = f(X_{t}^{x})
            - f(x)
            - \int_{0}^{t}g(X_{s}^{x})ds
        \end{align}
        と表せるが，$f, g$: 有界より $M$ は有界 CLM.
        各 $n\ge1$ に対し $M^n:=(M_{t\wedge n})_{t\ge0}$ を考えると $\forall t\ge0$ に対し
        \begin{align}
            \lvert M_{t\wedge n}\rvert
            &= \lvert f(X_{t\wedge n}^{x})
            - f(x)
            - \int_{0}^{t\wedge n}g(X_{s}^{x})ds\rvert \\
            &\le 2\lVert f\rVert + n\lVert g\rVert.
        \end{align}
        
        よって Proposition 4.7 (ii) から $M^n$: UIM なので $n$ の任意性から $M$: martingale.
        特に $(f(X_{t}^{x}) - \int_{0}^{t}g(X_{s}^{x})ds)_{t\ge0}$ も martingale.
        したがって Theorem 6.14 より $f\in D(L)$ かつ $Lf=g$ が言える．
    \end{enumerate}
\end{proof}

\begin{screen}
    \begin{cor}\label{cor:808}
        $(X_{t})_{t\ge0}$: filtered probability space $(\Omega, \mathcal{F}, (\mathcal{F}_t), P)$ 上の $E(\sigma, b)$ の解 \\
        $\implies (X_{t})_{t\ge0}$ は strong Markov property を満たす：
        $T$: stopping time, $\Phi:C(\mathbb{R}_{+}, \mathbb{R}^d)\to\mathbb{R}_{+}$: Borel 可測関数に対し
        \begin{align}
            E[\bm{1}_{\{T<\infty\}}\Phi(X_{T+t}, t\ge0)\mid\mathcal{F}_{T}]
            = \bm{1}_{\{T<\infty\}}\mathbb{E}_{X_{T}}[\Phi].
        \end{align}

        ただし $\forall x\in\mathbb{R}^d$ に対し $\mathbb{P}_{x}$ は $E_{x}(\sigma, b)$ の任意の解の $C(\mathbb{R}_{+}, \mathbb{R}^d)$ 上の分布を表す．
    \end{cor}
\end{screen}

\begin{proof}
    Theorem 6.17 を適用すれば十分．
    あるいは Theorem 8.6 の証明と同様に，stopping time $T$ に Theorem 8.6 の証明における決定論的な時刻 $s$ と同じ役割を持たせ，BM の strong Markov property (Theorem 2.20) を用いて議論することもできる．
\end{proof}

確率微分方程式の解として得られる連続な sample paths を持つ Markov 過程を \textbf{diffusion process（拡散過程）}と呼ぶことがある（$\mathbb{R}^d$ または多様体上の連続な sample paths を持つ強 Markov 過程を拡散過程と呼ぶ流儀もある）．
なお，ここで考えている Lipschitz の設定でも，Theorem 8.7 は生成作用素 $L$ を完全に特定するものではなく，領域 $D(L)$ の部分集合に対する作用に過ぎない：Chapter 6 で既に述べたように，領域を完全に記述することはしばしば非常に困難である．
しかしながら，多くの場合 Theorem 8.7 で与えられるような生成作用素の部分的な情報が，過程の確率法則を特徴づけるのに十分であることを示すことができる．
この観察は Stroock と Varadhan による古典的な本 [77] で展開されており，martingale 問題の強力な理論の中核をなすものである．

少なくとも $C_{c}^2(\mathbb{R}^d)$ に限定した場合，生成作用素 $L$ は 2 階微分作用素である．
確率微分方程式 $E(\sigma, b)$ は，前章で述べた BM と Laplace 演算子の関係のように，この微分作用素に関する多くの解析結果に確率論的アプローチ（と同時に解釈）を与えることができるものである．
確率微分方程式と偏微分方程式の関連については，Durrett [18, Chapter 9] と Friedman [26, 27] を参照されたい．
このような確率と解析の結びつきは，確率微分方程式の定義と研究の重要な動機であった．


\subsection{A Few Examples of Stochastic Differential Equations}

$d=1$ とする．

\subsubsection{The Ornstein-Uhlenbeck Process}

$\lambda>0$ とする．
確率微分方程式
\begin{align}
    dX_{t}
    = dB_{t} - \lambda X_{t}dt
\end{align}
の解を（1 次元）\textbf{Ornstein-Uhlenbeck 過程}という．
It\^{o}'s formula を適用することで，解は
\begin{align}
    X_{t}
    = X_{0}e^{-\lambda t}
    + \int_{0}^{t}e^{-\lambda(t-s)}dB_{s}
\end{align}
とわかる．

\begin{screen}
    $\because)$
    $f(t, x)=e^{\lambda t}x$ に対して It\^{o}'s formula を適用すると
    \begin{align}
        f(t, X_{t})
        = f(0, X_{0})
        + \int_{0}^{t}\frac{\partial f}{\partial t}(s, X_{s})ds
        + \int_{0}^{t}\frac{\partial f}{\partial x}(s, X_{s})dX_{s}
        + \frac{1}{2}\int_{0}^{t}\frac{\partial^2 f}{\partial x^2}(s, X_{s})d\langle X, X\rangle_{s}
    \end{align}
    より
    \begin{align}
        e^{\lambda t}X_{t}
        &= X_{0}
        + \int_{0}^{t}\lambda e^{\lambda s}X_{s}ds
        + \int_{0}^{t}e^{\lambda s}dX_{s} \\
        &= X_{0}
        + \int_{0}^{t}\lambda e^{\lambda s}X_{s}ds
        + \int_{0}^{t}e^{\lambda s}dB_{s} 
        - \int_{0}^{t}\lambda e^{\lambda s}X_{s}ds \\
        &= X_{0}
        + \int_{0}^{t}e^{\lambda s}dB_{s}.
    \end{align}
    \begin{align}
        \therefore X_{t}
        = X_{0}e^{-\lambda t}
        + \int_{0}^{t}e^{-\lambda(t-s)}dB_{s}.
    \end{align}
\end{screen}

確率積分は Wiener 積分（決定論的な積分）なので，$B$ から生成される Gaussian space に属することに注意（つまり $E[\int_{0}^{t}e^{-\lambda(t-s)}dB_{s}]=0$）．

\begin{enumerate}[label=(\roman*)]
    \item
    $X_{0}=x\in\mathbb{R}$ のとき：
    $X$ は平均関数
    \begin{align}
        m(t)
        := E[X_{t}]
        = xe^{-\lambda t},
    \end{align}
    共分散関数
    \begin{align}
        K(s, t)
        &:= \operatorname{cov}(X_{s}, X_{t}) \\
        &= E[\int_{0}^{s}e^{-\lambda(s-u)}dB_{u}\int_{0}^{t}e^{-\lambda(t-v)}dB_{v}] \\
        &= e^{-\lambda(t+s)}E[\int_{0}^{s}e^{\lambda u}dB_{u}\int_{0}^{t}e^{\lambda v}dB_{v}] \\
        &= e^{-\lambda(t+s)}\frac{e^{2\lambda(t\wedge s)}-1}{2\lambda} \\
        &= \frac{e^{-\lambda\lvert t-s\rvert}-e^{-\lambda(t+s)}}{2\lambda}
    \end{align}
    を持つ．

    \begin{screen}
        $\because)$
        \begin{align}
            E[\int_{0}^{s}e^{\lambda u}dB_{u}\int_{0}^{t}e^{\lambda v}dB_{v}]
            &= 
            \begin{cases}
                \displaystyle E[\int_{0}^{s}e^{\lambda u}dB_{u}\int_{0}^{s}e^{\lambda v}\bm{1}_{[0, t]}dB_{v}] & (s>t) \\
                \displaystyle E[\int_{0}^{t}e^{\lambda u}\bm{1}_{[0, s]}dB_{u}\int_{0}^{t}e^{\lambda v}\bm{1}_{[0, t]}dB_{v}] & (s\le t)
            \end{cases} \\
            &= 
            \begin{cases}
                \displaystyle \int_{0}^{t}e^{2\lambda u}du & (s>t) \\
                \displaystyle \int_{0}^{s}e^{2\lambda u}du & (s\le t)
            \end{cases} \\
            &= \int_{0}^{t\wedge s}e^{2\lambda u}du
            = \frac{e^{2\lambda(t\wedge s)}-1}{2\lambda}.
        \end{align}
    \end{screen}
    
    \item
    $X_{0}$ が正規分布 $\mathcal{N}(0, 1/2\lambda)$ に従うとき：
    $E[X_0]=0, E[X_0^2]=1/2\lambda$ より
    \begin{itemize}
        \item 
        $m(t):=E[X_t]=0.$
        \item 
        \begin{align}
            K(s, t)
            &:= \operatorname{cov}(X_{s}, X_{t}) \\
            &= E[(X_s-E[X_s])(X_t-E[X_t])]
            = E[X_s X_t] \\
            &= E[(X_0e^{-\lambda s}+\int_{0}^{s}e^{-\lambda(s-u)}dB_{u})
            (X_0e^{-\lambda t}+\int_{0}^{t}e^{-\lambda(t-v)}dB_{v})] \\
            &= E[X_0^2]e^{-\lambda(t+s)}
            + E[\int_{0}^{s}e^{-\lambda(s-u)}dB_{u}\int_{0}^{t}e^{-\lambda(t-v)}dB_{v}] \\
            &= \frac{e^{-\lambda(t+s)}+e^{-\lambda\lvert t-s\rvert}-e^{-\lambda(t+s)}}{2\lambda}
            = \frac{e^{-\lambda\lvert t-s\rvert}}{2\lambda}.
        \end{align}

        よって，このとき $X$ は正規分布 $\mathcal{N}(0, e^{-\lambda\lvert t-s\rvert}/2\lambda)$ に従う centered Gaussian process.
        さらに $X$ の共分散関数 $K(s, t)$ は $t-s$ にのみ依存して定まるので，Ornstein-Uhlenbeck 過程は $\mathbb{R}_+$ で添え字付けられた stationary Gaussian process であり，Markov 過程である．
    \end{itemize}
\end{enumerate}

\subsubsection{Geometric Brownian Motion}

$\sigma>0, r\in\mathbb{R}$ とする．
確率微分方程式
\begin{align}
    dX_t
    = \sigma X_t dB_t
    + rX_t dt
\end{align}
の解をパラメータ $\sigma, r$ を持つ \textbf{geometric Brownian motion（幾何ブラウン運動）}という．
It\^{o}'s formula を適用することで，解は
\begin{align}
    X_t
    = X_0\exp{(\sigma B_t+(r-\frac{\sigma^2}{2})t)}
\end{align}
とわかる．

\begin{screen}
    $\because) f(x)=\log x$ に対して It\^{o}'s formula を適用すると，$\langle X, X\rangle_t=\int_0^t \sigma^2 X_s^2 ds\implies d\langle X, X\rangle_s=\sigma^2 X_s^2 ds$ であることから
    \begin{align}
        \log{X_t}
        &= \log{X_0}
        + \int_0^t\frac{1}{X_s}(\sigma X_s dB_s+rX_s ds)
        -\frac{1}{2}\int_0^t \frac{1}{X_s^2}\sigma^2 X_s^2 ds \\
        &= \log{X_0}
        + \sigma B_t
        + rt
        -\frac{\sigma^2}{2}t \\
        &= \log(X_0\exp(\sigma B_t+(r-\frac{\sigma^2}{2})t))
    \end{align}
    \begin{align}
        \therefore X_t
        = X_0\exp(\sigma B_t+(r-\frac{\sigma^2}{2})t).
    \end{align}
\end{screen}

特に $X_0\ge0$ ならば，解は $t\ge0$ で非負値をとる．
幾何 BM は金融数学の Black-Scholes モデルに使われる．
理由としては，互いに素な時間間隔に対応する連続的な比率
\begin{align}
    \frac{X_{t_2}-X_{t_1}}{X_{t_1}}, 
    \frac{X_{t_3}-X_{t_2}}{X_{t_2}}, \dotsb, 
    \frac{X_{t_n}-X_{t_{n-1}}}{X_{t_{n-1}}}
\end{align}
が独立である，という経済学における仮定に由来するが，これは BM の独立増分性に他ならない．

\end{document}
